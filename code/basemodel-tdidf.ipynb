{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import re\nimport tqdm\nimport spacy\nimport torch\nimport random\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport scipy.sparse\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nimport nltk\nfrom nltk.corpus import stopwords\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:00:50.298140Z","iopub.execute_input":"2022-05-01T14:00:50.298362Z","iopub.status.idle":"2022-05-01T14:01:01.643077Z","shell.execute_reply.started":"2022-05-01T14:00:50.298337Z","shell.execute_reply":"2022-05-01T14:01:01.642357Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"STOPWORDS=stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:01:01.644609Z","iopub.execute_input":"2022-05-01T14:01:01.644836Z","iopub.status.idle":"2022-05-01T14:01:01.654012Z","shell.execute_reply.started":"2022-05-01T14:01:01.644804Z","shell.execute_reply":"2022-05-01T14:01:01.653285Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Parsing new dataset","metadata":{}},{"cell_type":"code","source":"def handle_apos(text):\n    text = re.sub(\"'re\", \" are\", text)\n    text = re.sub(\"'m\", \" am\", text)\n    text = re.sub(\"'ll\", \" will\", text)\n    text = re.sub(\"'ve\", \" have\", text)\n    text = re.sub(\"'d\", \" would\", text)\n    text = re.sub(\"'t\", \" not\", text)\n    return text\n\ndef handle_punctuation(text):\n    text = text.replace(\".\", \" \")\n    text = text.replace(\",\", \" \")\n    text = text.replace(\"!\", \" \")\n    text = text.replace(\"?\", \" \")\n    text = text.replace(\";\", \" \")\n    text = text.replace(\":\", \" \")\n    text = text.replace(\"-\", \" \")\n    text = text.replace(\"(\", \" \")\n    text = text.replace(\")\", \" \")\n    text = text.replace(\"[\", \" \")\n    text = text.replace(\"]\", \" \")\n    text = text.replace(\"{\", \" \")\n    text = text.replace(\"}\", \" \")\n    text = text.replace(\"/\", \" \")\n    text = text.replace(\"\\\\\", \" \")\n    text = text.replace(\"*\", \" \")\n    text = text.replace(\"+\", \" \")\n    text = text.replace(\"=\", \" \")\n    text = text.replace(\"#\", \" \")\n    text = text.replace(\"%\", \" \")\n    text = text.replace(\"$\", \" \")\n    text = text.replace(\"@\", \" \")\n    text = text.replace(\"&\", \" \")\n    text = text.replace(\"^\", \" \")\n    text = text.replace(\"|\", \" \")\n    text = text.replace(\"~\", \" \")\n    text = text.replace(\"`\", \" \")\n    text = text.replace(\"'\", \"\")\n    text = text.replace(\"\\\"\", \" \")\n    text = text.replace(\"<\", \" \")\n    text = text.replace(\">\", \" \")\n    text = text.replace(\"  \", \" \")\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:01:01.655598Z","iopub.execute_input":"2022-05-01T14:01:01.655888Z","iopub.status.idle":"2022-05-01T14:01:01.669419Z","shell.execute_reply.started":"2022-05-01T14:01:01.655806Z","shell.execute_reply":"2022-05-01T14:01:01.668799Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def stop_words(text):\n    text=text.split()\n    re=[]\n    for x in text:\n        if x not in STOPWORDS:\n            re.append(x)\n    return \" \".join(re)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:01:01.670958Z","iopub.execute_input":"2022-05-01T14:01:01.672607Z","iopub.status.idle":"2022-05-01T14:01:01.681659Z","shell.execute_reply.started":"2022-05-01T14:01:01.672567Z","shell.execute_reply":"2022-05-01T14:01:01.680861Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Tfidf Implementation","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/domaintermextraction/data_sw.csv')\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:05:03.840643Z","iopub.execute_input":"2022-05-01T14:05:03.841110Z","iopub.status.idle":"2022-05-01T14:05:03.880305Z","shell.execute_reply.started":"2022-05-01T14:05:03.841073Z","shell.execute_reply":"2022-05-01T14:05:03.879530Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                             content  category\n0  quarterly profits us media giant timewarner ju...  business\n1  owners embattled russian oil giant yukos ask b...  business\n2  british airways blamed high fuel prices drop p...  business\n3  shares uk drinks food firm allied domecq risen...  business\n4  japans economy teetered brink technical recess...  business","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quarterly profits us media giant timewarner ju...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>owners embattled russian oil giant yukos ask b...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>british airways blamed high fuel prices drop p...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>shares uk drinks food firm allied domecq risen...</td>\n      <td>business</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>japans economy teetered brink technical recess...</td>\n      <td>business</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data={}\narr=[\"business\",\"tech\",\"sport\",\"politics\",\"entertainment\"]\nfor i in arr:\n    data[i]=np.array(df[df[\"category\"]==i][\"content\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:05:04.154903Z","iopub.execute_input":"2022-05-01T14:05:04.155268Z","iopub.status.idle":"2022-05-01T14:05:04.165157Z","shell.execute_reply.started":"2022-05-01T14:05:04.155237Z","shell.execute_reply":"2022-05-01T14:05:04.164358Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def sort_coo(coo_matrix):\n    tuples = zip(coo_matrix.col, coo_matrix.data)\n    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n\ndef extract_topn_from_vector(feature_names, sorted_items, topn=10):\n    sorted_items = sorted_items[:topn]\n    score_vals = []\n    feature_vals = []\n    for idx, score in sorted_items:\n        fname = feature_names[idx]\n        score_vals.append(round(score, 3))\n        feature_vals.append(feature_names[idx])\n    results= {}\n    for idx in range(len(feature_vals)):\n        results[feature_vals[idx]]=score_vals[idx]\n    return results\n\ndef get_top_nK_words(corpus, K=1, n=None):\n    vec1 = CountVectorizer(stop_words=STOPWORDS, ngram_range=(K,K)).fit(corpus)\n    bag_of_words = vec1.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in     \n                  vec1.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], \n                reverse=True)\n    temp=words_freq[:n]\n    dic={}\n    for i in temp:\n        dic[i[0]]=i[1]\n    return dic\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:15:04.164731Z","iopub.execute_input":"2022-05-01T14:15:04.165234Z","iopub.status.idle":"2022-05-01T14:15:04.175653Z","shell.execute_reply.started":"2022-05-01T14:15:04.165197Z","shell.execute_reply":"2022-05-01T14:15:04.174798Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"label=[]\nngram=[]\nkeywd=[]\nfreqq=[]\nalpha=[]\nK_arr=[1,2,3]\nK=3  # n-gram \nfor key_lb in arr:\n    cv=CountVectorizer(stop_words=STOPWORDS,ngram_range=(K,K))\n    word_count_vector=cv.fit_transform(data[key_lb].tolist())\n    word_count_vector.shape\n    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n    tfidf_transformer.fit(word_count_vector)\n    docs=data[key_lb].tolist()\n    unigram=[]\n    for i in range(data[key_lb].shape[0]):\n        n=10\n        feature_names=cv.get_feature_names()\n        doc=docs[i]\n        tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n        sorted_items=sort_coo(tf_idf_vector.tocoo())\n        keywords=extract_topn_from_vector(feature_names,sorted_items,n)\n        for k in keywords:\n            unigram.append([k,keywords[k]])\n    unigram.sort(key=lambda y:y[1], reverse=True)\n    val=get_top_nK_words(data[key_lb],K)\n    for j in unigram:\n        label.append(key_lb)\n        ngram.append(str(K)+\"-gram\")\n        keywd.append(j[0])\n        freqq.append(val[j[0]])\n        alpha.append(j[1])\n","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:22:45.796404Z","iopub.execute_input":"2022-05-01T14:22:45.796684Z","iopub.status.idle":"2022-05-01T14:24:06.322242Z","shell.execute_reply.started":"2022-05-01T14:22:45.796655Z","shell.execute_reply":"2022-05-01T14:24:06.321513Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_f = {'n-gram': ngram, 'domain': label,'keyword':keywd,'frequency':freqq,'tfidf-score':alpha}\ndf = pd.DataFrame(data_f)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:24:06.323571Z","iopub.execute_input":"2022-05-01T14:24:06.323795Z","iopub.status.idle":"2022-05-01T14:24:06.355493Z","shell.execute_reply.started":"2022-05-01T14:24:06.323765Z","shell.execute_reply":"2022-05-01T14:24:06.354627Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"   n-gram    domain                      keyword  frequency  tfidf-score\n0  3-gram  business                 bn rupees bn          8        0.269\n1  3-gram  business      standard chartered said          5        0.245\n2  3-gram  business           mr spitzers office          3        0.226\n3  3-gram  business  financial ombudsman service          3        0.218\n4  3-gram  business                ms mohd saaid          3        0.217","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n-gram</th>\n      <th>domain</th>\n      <th>keyword</th>\n      <th>frequency</th>\n      <th>tfidf-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3-gram</td>\n      <td>business</td>\n      <td>bn rupees bn</td>\n      <td>8</td>\n      <td>0.269</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3-gram</td>\n      <td>business</td>\n      <td>standard chartered said</td>\n      <td>5</td>\n      <td>0.245</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3-gram</td>\n      <td>business</td>\n      <td>mr spitzers office</td>\n      <td>3</td>\n      <td>0.226</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3-gram</td>\n      <td>business</td>\n      <td>financial ombudsman service</td>\n      <td>3</td>\n      <td>0.218</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3-gram</td>\n      <td>business</td>\n      <td>ms mohd saaid</td>\n      <td>3</td>\n      <td>0.217</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.to_csv('./tfidf_trigram_fre.csv')  ","metadata":{"execution":{"iopub.status.busy":"2022-05-01T14:25:12.262963Z","iopub.execute_input":"2022-05-01T14:25:12.263243Z","iopub.status.idle":"2022-05-01T14:25:12.339391Z","shell.execute_reply.started":"2022-05-01T14:25:12.263215Z","shell.execute_reply":"2022-05-01T14:25:12.338723Z"},"trusted":true},"execution_count":47,"outputs":[]}]}